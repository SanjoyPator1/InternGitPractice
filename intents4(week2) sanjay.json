{
	"intents":[
				{
					"tag":"reinforcement learning",
					"patterns":[
									"what is reinforcement learning",
									"what do you mean by reinforcemnet learning",
									"define reinforcement learning"
								],
					"responses":[
"Reinforcement Learning(RL) is a type of machine learning technique that enables an agent to learn in an interactive environment by trial and error using feedback from its own actions and experiences. "
								],
					"context":[
								""
							   ]
				},
				{
					"tag":"relation between reinforcement learning and machine learning",
					"patterns":[
									"how machine learning and reinforcement learning are connected",
									"what is the realtion between reinforcement learning techniques and machine learning",
									"how reinforcement learning and machine learning are related to each other"
								],
					"responses":[
"Though both supervised and reinforcement learning use mapping between input and output, unlike supervised learning where feedback provided to the agent is correct set of actions for performing a task, reinforcement learning uses rewards and punishment as signals for positive and negative behavior. As compared to unsupervised learning, reinforcement learning is different in terms of goals. While the goal in unsupervised learning is to find similarities and differences between data points, in reinforcement learning the goal is to find a suitable action model that would maximize the total cumulative reward of the agent."
								],
				     "context":[
									""
								]
				},
				{
					"tag":"key terms realted to reinforcement learning",
					"patterns":[
									"mention some key terms realted to reinforcement learning problem",
									"what are the general key terms realted to reinforcement learning problems",
									"name some of the key terms realted to reinforcement learning problems"
								],
					"responses":[
"1.)Environment​: Physical world in which the agent operates 2.)State​: Current situation of the agent 3.)Reward​: Feedback from the environment 4.)Policy​: Method to map agent’s state to actions Value​: Future reward that an agent would receive by taking an action in a particular state."
								],
					"context":[
								""
							   ]
				},
				{
					"tag":"formulation of a reinforcement problem",
					"patterns":[
									"How to formulate a basic reinforcement Learning problem",
									"how to construct the solution of a reinforcement learning",
									"how to build a optimal solution for a reinforcement learning problem"
								],
					"responses":[
"A Reinforcement Learning problem can be best explained through games. Let’s take the game of PacMan where the goal of the agent (PacMan) is to eat the food in the grid while avoiding the ghosts on its way. The grid world is the interactive environment for the agent. PacMan receives a reward for eating food and punishment if it gets killed by the ghost (loses the game). The states are the location of PacMan in the grid world and the total cumulative reward is PacMan winning the game. In order to build an optimal policy, the agent faces the dilemma of exploring new states while maximizing its reward at the same time. This is called ​Exploration vs Exploitation trade-off​. Markov Decision Processes (MDPs)​ are mathematical frameworks to describe an environment in reinforcement learning and almost all RL problems can be formalized using MDPs.  An MDP consists of a set of finite environment states S, a set of possible actions A(s) in each state, a real valued reward function R(s) and a transition model P(s’, s | a). However, real world environments are more likely to lack any prior knowledge of environment dynamics. Model-free RL methods come handy in such cases. Q-learning​ is a commonly used model free approach which can be used for building a self-playing PacMan agent. It revolves around the notion of updating Q values which denotes value of doing action ​a in state ​s ​ . The value update rule is the core of the Q-learning algorithm."
								],
					"context":[
									""
							  ]
				},
				{
					"tag":"reinforcement learning algorithms",
					"patterns":[
									"what are some of the most used reinforcement learning algorithms",
									"name some prefferd algorithms of reinforcement learning",
									" What are some most used Reinforcement Learning algorithms"
								],
					"responses":[
"Q-learning and SARSA (State-Action-Reward-State-Action) are two commonly used model-free RL algorithms. They differ in terms of their exploration strategies while their exploitation strategies are similar. While Q-learning is an off-policy method in which the agent learns the value based on action a* derived from the another policy, SARSA is an on-policy method where it learns the value based on its current action ​a ​ derived from its current policy. These two methods are simple to implement but lack generality as they do not have the ability to estimate values for unseen states. This can be overcome by more advanced algorithms such as ​Deep Q-Networks​ which use Neural Networks to estimate Q-values. But DQNs can only handle discrete, low-dimensional action spaces. DDPG(Deep Deterministic Policy Gradient)​is a model-free, off-policy, actor-critic algorithm that tackles this problem by learning policies in high dimensional, continuous action spaces. "
								],
					"context":[
									""
							   ]
				},
				{
					"tag":"applications of reinforcement learning",
					"patterns":[
									"what are some of the most practical applications of reinforcement learning",
									"name some areas where reinforcement learning can be used",
									"what are some of the fields where we can use reinforcement learning" 
								],
					"responses":[

	"RL is quite widely used in building AI for playing computer games. ​AlphaGo Zero​ is the first computer program to defeat a world champion in the ancient Chinese game of Go. Others include ATARI games, Backgammon, etc In robotics and industrial automation,RL is used to enable the robot to create an efficient adaptive control system for itself which learns from its own experience and behavior.​DeepMind’s work​ on Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Policy updates is a good example of the same.Other applications of RL include text summarization engines, dialog agents (text, speech) which can learn from user interactions and improve with time, learning optimal treatment policies in healthcare and RL based agents for online stock trading."
								],
					"context":[
									""
								]
				},
				{
					"tag":"resources to learn reinforcement learning",
					"patterns":[
									"how can i get stareted with reinforcement learning",
									"what are the resources that one can avial to learn reinforcement learning",
									"what are some of the tutorials and books available for reinforcement learning",
									"name a book to learn reinforcement learning"
								],
					"responses":[
"Reinforcement Learning-An Introduction​, a book by the father of Reinforcement Learning- Richard Sutton​ and his doctoral advisor ​Andrew Barto​. An online draft of the book is available here http://incompleteideas.net/book/the-book-2nd.html Teaching material​from ​David Silver​ including video lectures is a great introductory course on RL. Here’s another ​technical tutorial​ on RL by ​Pieter Abbeel​ and ​John Schulman​ (Open AI/ Berkeley AI Research Lab). For getting started with building and testing RL agents, This blog​ on how to train a Neural Network ATARI Pong agent with Policy Gradients from raw pixels by​ Andrej Karpathy​ will help you get your first Deep Reinforcement Learning agent up and running in just 130 lines of Python code. "
								],
					"context":[
									""
							   ]
				},
				{
					"tag":"types of reinforcement learning",
					"patterns":[
									"what are the types of reinforcement learning",
									"mention the different types of reinforcement learning",
									"what are the different kinds of reinforcement learning"
								],
					"responses":[
"Types of Reinforcement:​ There are two types of Reinforcement: 1.) Positive – Positive Reinforcement is defined as when an event, occurs due to a particular behavior, increases the strength and the frequency of the behavior. In other words, it has a positive effect on behavior. 2.) Negative – Negative Reinforcement is defined as strengthening of a behavior because a negative condition is stopped or avoided. "
								],
					"context":[
								""
								]
				},
				{
					"tag":"advantages and disadvanatages of reinforcement learning",
					"patterns":[
									"what are the advantages and disadvantages of reinforcement learning",
									"how reinforcement learning can be advanategeous and disadvantegeous",
									"list some of the benefits and losses of using reinforcement learning"
								],
					"responses":[
"Advantages of reinforcement learning are: 1.Maximizes Performance 2.Sustain Change for a long period of time 3.) Increases Behavior 4.)Provide defiance to minimum standard of performance. The disadvanatges are: 1.)Too much Reinforcement can lead to overload of states which can diminish the results 2.)It Only provides enough to meet up the minimum behavior "
								],
					"context":[
								""
							  ]
				},
				{
					"tag":"why rl is hard",
					"patterns":[
									"why RL is hard",
									"why reinforcement learning is hard to implement",
									"why some people finds it tough to learn reinforcement learning"
								],
					"responses":[
"You try to learn a function via incomplete information. f(x) = maximum expected ∞ ∑ t=0 rt + noise (E) + non-linearity (approximation issues, CV, stability) + many local optima (counter-intuitive results) + exploration / exploitation tradeoff for sampling"
								],
					"context":[
								""
							   ]
				 },
			
				 {
						"tag":"solution of cartpole problem",
						"patterns":[
										"propose a solution to the cartpole problem using reinforcement learning",
										"how reinforcement learning can help in solving the cartpole problem",
										"how cartpole problem can be resolved using reinforcement learning"
									],
						"responses":[
"Since RL is a form of learning characterized by trial and error response to actions and its effect on the environment, it makes sense to model the cartpole system via RL, since the cartpole system is heavily subject to various parameter changes while having a clearly defined agent-action-environment-reward schema. The agent is the controller or algorithm which controls the movement of the cart. The action is the physical movement of the cartpole in response to various forces and torques following the swing-up phase.The environment is the physical setting of the cart pole in regard to the constrained area of the system. The reward is the ability of the cartpole to achieve sustained balance in its current state. We will now identify the specific actions and states of the cartpole problem."
									],
						"context":[
									""
								  ]
				},
				{
						"tag":" 'action' in reinforcement learning",
						"patterns":[
										"what do you mean by action in reinforcement learning",
										"what is the term 'action' means in reagrd to reinforcement learning",
										"define action "
									],
						"responses":[
										"All the possible moves that the agent can take."
									],
						"context":[
									""
									]
				},
				{
					"tag":" 'agent' in reinforcement learning",
					"patterns":[
									"what is agent in reinforcement learning",
									"what is the term reinforcement learning means in regards to reinforcement learning",
									"define agent"
							   ],
					"responses":[
" ​a hypothetical entity which performs actions in an environment to gain some reward."
								],
					"context":[
									""
								]
				},
				{
					"tag":" 'value' in reinforcement learning",
					"patterns":[
									"what is the term 'value' means in regards to reinforcement learning",
									"what is value in reinforcement learning",
									"define value"
								],
					"responses":[
"The expected long-term return with discount, as opposed to the short-term reward ​R​. ​Vπ(s)​, is defined as the expected long-term return of the current state ​s​ under policy ​π​."
								],
					"context":[
								""
							  ]
				},
				{
					"tag":"q-value or action-value",
					"patterns":[
									"what do you mean by action value",
									"what do you mean by q-value",
									"what is q-value or action-value in the context of reinforcement learning",
									"what is q-value or action-value in reinforcement learning"
								],
					"responses":[
"-Q-value is similar to Value, except that it takes an extra parameter, the current action ​a​. ​Qπ(s, a) refers to the long-term return of the current state ​s​, taking action ​a​ under policy ​π​. "
								],
					"context":[
								""
							  ]
				},
				{
					"tag":"value-based learning",
					"patterns":[
									"what is value-based learning",
									"what is value-based learning in reinforcement learning",
									"define value-based learning"
								],
					"responses":[
" ​In a value-based reinforcement learning method, you try to maximize a value function ​V(s)​. As defined in the terminology previously, ​Vπ(s)​ is the expected long-term return of the current state ​s​ under policy ​π​. Thus, ​V(s)​ is the value of reward which the agent expects to gain in the future upon starting at that state ​s​."
								],
					"context":[
								""
							   ]
				},
				{
					"tag":"policy-based reinforcement learning",
					"patterns":[
									"define policy-based reinforcement learning",
									"what is policy-based reinforcement learning",
									"what do you mean by policy-based reinforcement learning"
								],
					"responses":[
" ​in a policy-based reinforcement learning method, you try to come up with a policy such that the action performed at each state is optimal to gain maximum reward in the future. Here, no value function is involved. We know that the policy ​π​ determines the next action ​a​ at any state ​s​. There are two types of policy-based RL methods - 1.)Deterministic: ​at any state ​s​, the same action ​a​ is produced by the policy ​π​. 2.) Stochastic: ​each action has a certain probability"
								],
					"context":[
								""
								]
				},
				{
					"tag":"model-based learning",
					"patterns":[
									"what is model-based learning",
									"define model-based learning",
									"what does the term model-based learning means"
								],
					"responses":[
" ​In this type of reinforcement learning, you create a virtual model for each environment, and the agent learns to perform in that specific environment. Since the model differs for each environment, there is no singular solution or algorithm for this type"
								],
					"context":[
									""
								]
				}
				
			]
	}